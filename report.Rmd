---
title: "ECON 771 -  Empirical Exercise 1"
author: "Emerson Hamer"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: pdflatex
header-includes:
  \usepackage{longtable}
---

# Introduction
This report discusses the treatment effect of insurance expansion across states on their amount of hospital uncompensated care. 

[Here](https://github.com/emersonhamer/EC-771-Empirical) is the Github Repo containing all necessary files to reproduce results in this report.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE,
                      fig.width = 10, fig.height = 5.5, fig.align = 'center')
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, stargazer, withr, fixest, modelsummary, did, HonestDiD, modelsummary, kableExtra, xtable)

load("analysis/did.RData")
```

# Q1. Summary statistics

Provide and discuss a table of simple summary statistics showing the mean, standard deviation, min, and max of hospital total revenues and uncompensated care over time.


```{r q1,  results = "asis"}

library(knitr)



# Output tables side by side 
options(xtable.comment = FALSE)
library(knitr)

# Generate the first table
xt_rev <- xtable(round(combined.rev.df, digits = 2),
                 caption = "Summary statistics of total hospital revenus")
names(xt_rev) <- c('Year', 'Mean', 'SD', 'Min', 'Max')
table1 <- knitr::kable(xt_rev, format = "latex", align = "c", booktabs = TRUE)

# Generate the second table
xt_unc <- xtable(round(combined.uncomp.df, digits = 2),
                 caption = "Summary statistics of uncompensated care")
names(xt_unc) <- c('Year', 'Mean', 'SD', 'Min', 'Max')
table2 <- knitr::kable(xt_unc, format = "latex", align = "c", booktabs = TRUE)

# Output tables side by side 
cat('\\begin{table}[!htb]\n')
cat('\\centering\n')
cat('\\begin{minipage}[b]{0.45\\textwidth}\n')
cat('\\caption{Summary Stats Hospital Revenues}\n')
cat('\\centering\n')
cat(table1)
cat('\\end{minipage}\n')
cat('\\hfill\n')  # Add horizontal space
cat('\\begin{minipage}[b]{0.45\\textwidth}\n')
cat('\\caption{Summary Stats Uncompensated Care}\n')
cat('\\centering\n')
cat(table2)
cat('\\end{minipage}\n')
cat('\\end{table}\n')
```
Comments:

The mean hospital revenue is increasing over time.  The highest maximum total revenue is reached in 2019, and the lowest minumum revenue is in 2010. The mean uncompensated care is generally increasing over time, with a small decrease from 2013-2015.  The highest maximum uncompensated care is reached in 2019, and the lowest minumum uncompensated care is in 2003.

\newpage


# Q2. Trend of mean hospital uncompensated care
Create a figure showing the mean hospital uncompensated care from 2003 to 2019. Show this trend separately by hospital ownership type (private not for profit and private for profit).
```{r q2, fig.width=8, fig.height=4}
library(gridExtra)

full_mean_unc_graph <- full_mean_unc_graph + 
  ggtitle("Figure 1: Mean Uncompensated Care") +
  theme(plot.title = element_text(size = 10))  # make title text smaller

mean_unc_bg_graph <- mean_unc_bg_graph + 
  ggtitle("Figure 2: Mean Uncompensated Care by Ownership Type") +
  theme(plot.title = element_text(size = 10))  # make title text smaller

grid.arrange(full_mean_unc_graph, mean_unc_bg_graph, ncol=2)
```

# Q3. Two-way fixed-effects (TWFE) regression model
Using a simple DD identification strategy, estimate the effect of Medicaid expansion on hospital uncompensated care using a traditional two-way fixed effects (TWFE) estimation:
\begin{equation}
y_{it} = \alpha_{i} + \gamma_{t} + \delta D_{it} + \varepsilon_{it},
\label{eq:dd}
\end{equation}
where $D_{it}=1(E_{i}\leq t)$ in Equation \ref{eq:dd} is an indicator set to 1 when a hospital is in a state that expanded as of year $t$ or earlier, $\gamma_{t}$ denotes time fixed effects, $\alpha_{i}$ denotes hospital fixed effects, and $y_{it}$ denotes the hospital's amount of uncompensated care in year $t$. Present four estimates from this estimation in a table: one based on the full sample (regardless of treatment timing); one when limiting to the 2014 treatment group (with never treated as the control group); one when limiting to the 2015 treatment group (with never treated as the control group); and one when limiting to the 2016 treatment group (with never treated as the control group). Briefly explain any differences.

\newpage
```{r q3}

dd.summary
```

Comments:

As we can see in the table above, the estimated treatment effects are similar accross all of the specifications. This suggests that the treatment effect is robust to different treatment timing. This is consistent with the assumption of the TWFE model that the treatment effect is constant across all treated groups.
  


# Q4. Event study
Estimate an "event study" version of the specification in part 3:
\begin{equation}
y_{it} = \alpha_{i} + \gamma_{t} +\sum_{\tau < -1} D_{it}^{\tau} \delta_{\tau} + \sum_{\tau>=0} D_{it}^{\tau} \delta_{\tau} + \varepsilon_{it},
\label{eq:event}
\end{equation}
where $D_{it}^{\tau} = 1(t-E_{i}=\tau)$ in Equation \ref{eq:event} is essentially an interaction between the treatment dummy and a relative time dummy. In this notation and context, $\tau$ denotes years relative to Medicaid expansion, so that $\tau=-1$ denotes the year before a state expanded Medicaid, $\tau=0$ denotes the year of expansion, etc. Estimate with two different samples: one based on the full sample and one based only on those that expanded in 2014 (with never treated as the control group).
```{r q4}
event1.plot = iplot(event.reg1, xlab = "Time to Treatment", main="Figure 3: Event Study - Full Sample")

event2.plot = iplot(event.reg2, xlab = "Year", main="Figure 4: Event Study - 2014 Expansion")

```


# Q5. Sun and Abraham (SA) estimator
Sun and Abraham (SA) show that the $\delta_{\tau}$ coefficients in Equation \@ref(eq:event) can be written as a non-convex average of all other group-time specific average treatment effects. They propose an interaction weighted specification:
\begin{equation}
y_{it} = \alpha_{i} + \gamma_{t} +\sum_{e} \sum_{\tau \neq -1} \left(D_{it}^{\tau} \times 1(E_{i}=e)\right) \delta_{e, \tau} + \varepsilon_{it}.
\label{eq:iwevent}
\end{equation}
Re-estimate your event study using the SA specification in Equation \ref{eq:iwevent}. Show your results for $\hat{\delta}_{e, \tau}$ in a Table, focusing on states with $E_{i}=2014$, $E_{i}=2015$, and $E_{i}=2016$.
\newpage

```{r q5}
names(sa.est) <- c('Period', 'Cohort','Estimate','p-value')
knitr::kable(sa.est, caption = 'Sun and Abraham Estimates', longtable = TRUE)
```

\newpage

# Q6. Event study graph on the SA estimator
Present an event study graph based on the results in part 5. Hint: you can do this automatically in `R` with the `fixest` package (using the `sunab` syntax for interactions), or with `eventstudyinteract` in `Stata`. These packages help to avoid mistakes compared to doing the tables/figures manually and also help to get the standard errors correct.
```{r q6}
sa.event.plot = iplot(sa.reg, xlab = "Time to Treatment", main = "Figure 5: Sun and Abraham Event Study")
```

\newpage

# Q7. Callaway and Sant'Anna (CS) estimator
Callaway and Sant'Anna (CS) offer a non-parametric solution that effectively calculates a set of group-time specific differences, $ATT(g,t)= E[y_{it}(g) - y_{it}(\infty) | G_{i}=g]$, where $g$ reflects treatment timing and $t$ denotes time. They show that under the standard DD assumptions of parallel trends and no anticipation, $ATT(g,t) = E[y_{it} - y_{i, g-1} | G_{i}=g] - E[y_{it} - y_{i,g-1} | G_{i} = \infty]$, so that $\hat{ATT}(g,t)$ is directly estimable from sample analogs. CS also propose aggregations of $\hat{ATT}(g,t)$ to form an overall ATT or a time-specific ATT (e.g., ATTs for $\tau$ periods before/after treatment). With this framework in mind, provide an alternative event study using the CS estimator. Hint: check out the `did` package in `R` or the `csdid` package in `Stata`.
```{r q7}
cs.plot <- cs.plot + 
  ggtitle("Figure 6: Event Study Using CS Estimates")

# Display the plot
cs.plot

```

\newpage

# Q8. Rambachan and Roth (RR) sentivity plot for the CS estimator
Rambachan and Roth (RR) show that traditional tests of parallel pre-trends may be underpowered, and they provide an alternative estimator that essentially bounds the treatment effects by the size of an assumed violation in parallel trends. One such bound RR propose is to limit the post-treatment violation of parallel trends to be no worse than some multiple of the pre-treatment violation of parallel trends. Assuming linear trends, such a relative violation is reflected by $$\Delta(\bar{M}) = \left\{ \delta : \forall t \geq 0, \lvert (\delta_{t+1} - \delta_{t}) - (\delta_{t} - \delta_{t-1}) \rvert \leq \bar{M} \times \max_{s<0} \lvert (\delta_{s+1} - \delta_{s}) - (\delta_{s} - \delta_{s-1}) \rvert \right\}.$$ The authors also propose a similar approach with what they call "smoothness restrictions," in which violations in trends changes no more than $M$ between periods. The only difference is that one restriction is imposed relative to observed trends, and one restriction is imposed using specific values. Using the `HonestDiD` package in `R` or `Stata`, present a sensitivity plot of your CS ATT estimates using smoothness restrictions, with assumed violations of size $M \in \left\{ 500, 1000, 1500, 2000 \right\}$. Check out the GitHub repo [here](https://github.com/pedrohcgs/CS_RR) for some help in combining the `HonestDiD` package with CS estimates. Note that you'll need to edit the function in that repo in order to use pre-specified smoothness restrictions. You can do that by simply adding `Mvec=Mvec` in the `createSensitivityResults` function for `type=smoothness`.

```{r q8}
cs.hd.plot <- cs.hd.plot + 
  ggtitle("Figure 7: Sensitivity Plot CS Estimates")

# Display the plot
cs.hd.plot
```

\newpage

# Q9. Discussions and findings
Discuss your findings and compare estimates from different estimators (e.g., are your results sensitive to different specifications or estimators? Are your results sensitive to violation of parallel trends assumptions?).

Comments: 

My results do not seem to be very sensitive to different specifications; they seem to be consistent across all the estimators. The results suggest that there is a causal relationship between insurance expansion and uncompensated care. My simple DD estimation suggests that insurance expansion caused a reduction in uncompensated care of about $18.7 million. This is consistent with the findings from the event study, Sun and Abraham estimator, and Callaway and Sant'Anna estimator. The results from the Rambachan and Roth sensitivity plot suggest that the results are not sensitive to the violation of parallel trends assumptions. 


# Q10. Reflection
Reflect on this assignment. What did you find most challenging? What did you find most surprising? 

Comments: 

The most challenging part of this assignment was learning how to create a replicable workflow. I found it challenging to keep track of all the different files and code that I needed to run. I also found it challenging to learn how to use the different packages and functions. I used this assignment as an opportunity to learn R, which added another level of complication.  The most surprising part of this assignment was how difficult it is to produce accurate results without knowing what the results should look like ahead of time.  Small changes in the code can produce large changes in the results, so I had to be very careful to track what I was changing and how it was affecting the results.

